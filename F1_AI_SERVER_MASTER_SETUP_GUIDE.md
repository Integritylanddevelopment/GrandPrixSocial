# üèéÔ∏è F1 AI SERVER - MASTER SETUP GUIDE
*Complete step-by-step guide to deploy your private F1 AI infrastructure*

---

## üéØ OVERVIEW

Transform your old desktop into a powerful F1 AI server that:
- ‚úÖ Runs Qwen3 LLM locally (no API costs)
- ‚úÖ Generates F1 content 24/7
- ‚úÖ Trains continuously from user feedback
- ‚úÖ Powers Fantasy League strategy features
- ‚úÖ Costs ~$10-15/month in electricity vs $800-1600/year cloud

---

## üìã PRE-FLIGHT CHECKLIST

### Hardware Requirements (Your Old Desktop):
- [ ] **CPU**: 4+ cores (8+ recommended)
- [ ] **RAM**: 8GB minimum (16GB+ recommended)
- [ ] **Storage**: 100GB free (250GB+ recommended)
- [ ] **Network**: Ethernet connection preferred
- [ ] **Power**: Can stay on 24/7

### What You'll Need:
- [ ] Ubuntu Server 22.04 LTS USB installer
- [ ] Router admin access (for port forwarding)
- [ ] 2-3 hours of setup time
- [ ] Coffee ‚òï

---

## üöÄ PHASE 1: WIPE & INSTALL UBUNTU SERVER

### Step 1.1: Create Ubuntu Installer
```bash
# Download Ubuntu Server 22.04 LTS
# Burn to USB using Rufus (Windows) or dd (Linux/Mac)
```

### Step 1.2: Install Ubuntu Server
1. Boot from USB on your old desktop
2. Select **Ubuntu Server (minimized)**
3. Configure:
   - **Hostname**: `f1-ai-server`
   - **Username**: `f1admin` (or your preference)
   - **Password**: Strong password
   - **SSH**: Enable OpenSSH server ‚úÖ
   - **Packages**: Select Docker (optional, we'll install manually)

### Step 1.3: First Boot
```bash
# SSH into your new server from your main machine
ssh f1admin@192.168.1.XXX  # Use your server's IP

# Update system
sudo apt update && sudo apt upgrade -y
```

---

## üîß PHASE 2: INSTALL F1 AI INFRASTRUCTURE

### Step 2.1: Run Main Setup Script
```bash
# Copy the setup script to your server
scp server-setup/ubuntu-server-setup.sh f1admin@192.168.1.XXX:~/

# Make executable and run
chmod +x ubuntu-server-setup.sh
./ubuntu-server-setup.sh
```

**This script installs:**
- Docker & Docker Compose
- Nginx web server
- Node.js runtime
- Security tools
- Creates F1 server directory structure
- Sets up Qwen3 docker-compose configuration

### Step 2.2: Start F1 Services
```bash
cd ~/f1-server

# Start all services
docker-compose up -d

# Check status
docker-compose ps

# View logs
docker-compose logs qwen3
```

### Step 2.3: Test Qwen3 API
```bash
# Wait 2-3 minutes for model download, then test
curl -X POST http://localhost:12434/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "qwen2.5:7b",
    "messages": [{"role": "user", "content": "Write a short F1 news headline about Max Verstappen"}],
    "max_tokens": 50
  }'
```

**Expected Response**: JSON with F1 content generated by Qwen3

---

## üåê PHASE 3: NETWORKING & SECURITY

### Step 3.1: Configure Security & Reverse Proxy
```bash
# Copy networking script
scp server-setup/networking-setup.sh f1admin@192.168.1.XXX:~/

# Make executable and run
chmod +x networking-setup.sh
./networking-setup.sh
```

### Step 3.2: Router Configuration
1. Access your router admin panel (usually `192.168.1.1`)
2. Find **Port Forwarding** settings
3. Add these rules:
   ```
   Service: SSH        External: 2222  Internal: 22    IP: [server-ip]
   Service: HTTPS      External: 443   Internal: 443   IP: [server-ip]
   Service: Qwen3-API  External: 12434 Internal: 12434 IP: [server-ip]
   Service: Health     External: 8080  Internal: 80    IP: [server-ip]
   ```

### Step 3.3: Get Your External IP
```bash
# Find your public IP
curl ifconfig.me

# Test external access
curl http://YOUR-PUBLIC-IP:8080/health
# Should return: "F1 AI Server is running"
```

---

## üîó PHASE 4: CONNECT YOUR DEVELOPMENT MACHINE

### Step 4.1: Update Your .env.local
On your main development machine, update `.env.local`:

```bash
# Existing Supabase config (keep these)
NEXT_PUBLIC_SUPABASE_URL=https://eeyboymoyvrgsbmnezag.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=your-anon-key
SUPABASE_SERVICE_ROLE_KEY=your-service-role-key

# NEW: Point to your F1 AI server
QWEN_API_URL=http://192.168.1.XXX:12434/v1/chat/completions  # Local IP
# OR for remote access:
# QWEN_API_URL=http://YOUR-PUBLIC-IP:12434/v1/chat/completions

# Optional: Fallback to OpenAI if server is down
OPENAI_API_KEY=your-openai-key-as-backup
```

### Step 4.2: Test Integration
```bash
# Start your development server
npm run dev

# Test F1 news generation (uses your AI server now)
curl http://localhost:3000/api/scrape-f1-news

# Test analytics tracking
open http://localhost:3000/analytics-test
```

---

## üìä PHASE 5: ENABLE LIVE TRAINING

### Step 5.1: Start Live Training System
```bash
# Enable continuous learning from user feedback
curl -X POST http://localhost:3000/api/training/start-live-training
```

### Step 5.2: Monitor Training Status
```bash
# Check training statistics
curl http://localhost:3000/api/training/start-live-training

# View training data
curl http://localhost:3000/api/analytics/generate-training-data
```

### Step 5.3: Manual Fine-Tuning (Future)
```bash
# Copy fine-tuning script to your server
scp scripts/fine-tune-qwen3.py f1admin@192.168.1.XXX:~/f1-server/

# When you have 100+ training examples:
ssh f1admin@192.168.1.XXX
cd ~/f1-server
python3 fine-tune-qwen3.py
```

---

## üéõÔ∏è PHASE 6: SERVER MANAGEMENT

### Daily Operations:
```bash
# SSH into server
ssh f1admin@192.168.1.XXX

# Check system status
htop                        # CPU/RAM usage
docker ps                  # Container status  
df -h                       # Disk usage
docker-compose logs qwen3   # AI model logs

# Restart services if needed
cd ~/f1-server
docker-compose restart qwen3
```

### Web Dashboards:
- **Portainer**: `http://server-ip:9000` (Docker management UI)
- **Health Check**: `http://server-ip/health` (Server status)
- **Nginx Status**: `http://server-ip/nginx_status` (Web server metrics)

### Backup Commands:
```bash
# Backup training data
rsync -av f1admin@server-ip:~/f1-server/training-data/ ./backups/

# Backup Docker volumes (models)
docker run --rm -v f1-server_qwen_models:/data -v $(pwd):/backup alpine \
  tar czf /backup/qwen-models-backup.tar.gz -C /data .
```

---

## üö® TROUBLESHOOTING

### Problem: Qwen3 Won't Start
```bash
# Check Docker logs
docker-compose logs qwen3

# Common fixes:
docker-compose down && docker-compose up -d  # Restart
docker system prune -f                        # Clean Docker cache
sudo reboot                                   # Restart server
```

### Problem: Can't Connect from Development Machine
```bash
# Test local connection first
ssh f1admin@192.168.1.XXX
curl http://localhost:12434/v1/chat/completions

# Check firewall
sudo ufw status

# Check port forwarding in router
curl http://YOUR-PUBLIC-IP:12434/v1/chat/completions
```

### Problem: Out of Memory
```bash
# Check memory usage
free -h

# Add swap space
sudo fallocate -l 4G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile  
sudo swapon /swapfile
```

---

## üìà PERFORMANCE EXPECTATIONS

### With 8GB RAM:
- **F1 Article Generation**: 3-5 seconds
- **Concurrent Requests**: 2-3 users
- **Daily Capacity**: 500+ articles

### With 16GB RAM:
- **F1 Article Generation**: 1-3 seconds  
- **Concurrent Requests**: 5-8 users
- **Daily Capacity**: 1000+ articles

### With 32GB+ RAM:
- **F1 Article Generation**: 1-2 seconds
- **Concurrent Requests**: 10+ users
- **Daily Capacity**: 2000+ articles
- **Future**: Run multiple AI models simultaneously

---

## üéØ SUCCESS METRICS

After setup completion, you should have:

- ‚úÖ **F1 AI Server** running 24/7 on your old desktop
- ‚úÖ **Qwen3 Model** generating F1 content locally  
- ‚úÖ **Live Training** learning from user interactions
- ‚úÖ **Zero Monthly Costs** (except ~$10-15 electricity)
- ‚úÖ **Complete Control** over your AI infrastructure
- ‚úÖ **Remote Access** from anywhere in the world
- ‚úÖ **Monitoring Dashboards** for system health
- ‚úÖ **Automatic Backups** of training data
- ‚úÖ **Foundation** for Fantasy League AI features

---

## üöÄ FUTURE EXPANSION IDEAS

Once your F1 AI server is stable:

### Month 2: Enhanced Features
- **Multiple AI Models**: News, Strategy, Fantasy specialists
- **Advanced Analytics**: User behavior prediction
- **Content Personalization**: AI adapts to individual users

### Month 3: Premium Features  
- **Fantasy League AI**: Automated lineup optimization
- **Strategy Coach**: Personalized race predictions
- **Market Analysis**: Driver/team performance forecasting

### Month 6: Advanced Infrastructure
- **Load Balancing**: Multiple AI model instances
- **Edge Caching**: Faster response times globally
- **ML Pipeline**: Automated model retraining
- **API Gateway**: Rate limiting, authentication

---

## ‚ö° QUICK START SUMMARY

1. **Install Ubuntu Server** on old desktop (30 min)
2. **Run setup scripts** from this repo (15 min)
3. **Configure router** port forwarding (10 min)
4. **Update .env.local** on dev machine (2 min)
5. **Test integration** with F1 site (5 min)
6. **Start live training** system (2 min)

**Total Time**: ~1 hour active work + waiting for downloads

**Result**: Your own private F1 AI infrastructure!

---

## üìû SUPPORT & NEXT STEPS

### If You Get Stuck:
1. Check the troubleshooting section above
2. Review the detailed setup files in `server-setup/` 
3. Test each component individually
4. Compare your setup to the expected configurations

### Ready to Begin?
Start with **PHASE 1** and work through each section systematically. Each phase builds on the previous one, so don't skip ahead!

**üèÅ Ready to transform that old desktop into an F1 AI powerhouse?**